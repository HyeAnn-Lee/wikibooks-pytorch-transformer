{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset`과 `Dataloader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` 클래스 기본형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, *arg, **kwarg):\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return tuple(data[index] for data in self.data.tensors)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.29 - 기본 구조 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor([\n",
    "    [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "    [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.30 - 데이터세트와 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.31 - 모델, 오차 함수, 최적화 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 2, bias=True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.32 - 데이터로더 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[0.5529, 0.1432],\n",
      "        [0.6248, 0.5299]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0849,  0.2816], requires_grad=True)], Cost : 0.109\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[0.7600, 0.0363],\n",
      "        [0.7724, 0.4537]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.3989,  0.0579], requires_grad=True)], Cost : 0.028\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 0.8654, -0.0183],\n",
      "        [ 0.8475,  0.4148]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5589, -0.0561], requires_grad=True)], Cost : 0.007\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 0.9191, -0.0461],\n",
      "        [ 0.8858,  0.3950]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6404, -0.1142], requires_grad=True)], Cost : 0.002\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 0.9465, -0.0602],\n",
      "        [ 0.9053,  0.3849]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6819, -0.1437], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 0.9604, -0.0674],\n",
      "        [ 0.9152,  0.3798]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7031, -0.1588], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 0.9675, -0.0711],\n",
      "        [ 0.9203,  0.3772]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7139, -0.1665], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 0.9712, -0.0730],\n",
      "        [ 0.9228,  0.3759]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7194, -0.1704], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 0.9730, -0.0739],\n",
      "        [ 0.9242,  0.3752]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7222, -0.1724], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 0.9740, -0.0744],\n",
      "        [ 0.9248,  0.3748]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7236, -0.1734], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 11000, Model : [Parameter containing:\n",
      "tensor([[ 0.9744, -0.0747],\n",
      "        [ 0.9252,  0.3747]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7243, -0.1739], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 12000, Model : [Parameter containing:\n",
      "tensor([[ 0.9747, -0.0748],\n",
      "        [ 0.9253,  0.3746]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7247, -0.1742], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 13000, Model : [Parameter containing:\n",
      "tensor([[ 0.9748, -0.0749],\n",
      "        [ 0.9254,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7249, -0.1743], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 14000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1744], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 15000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1744], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 16000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1745], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 17000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1745], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 18000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1745], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 19000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1745], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 20000, Model : [Parameter containing:\n",
      "tensor([[ 0.9749, -0.0749],\n",
      "        [ 0.9255,  0.3745]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7250, -0.1745], requires_grad=True)], Cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost /= len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.34 - 편향 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[ 0.7698, -0.0476],\n",
      "        [ 0.6970,  0.5259]], requires_grad=True)], Cost : 0.066\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[ 0.9606, -0.2022],\n",
      "        [ 0.7797,  0.4590]], requires_grad=True)], Cost : 0.041\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 1.1124, -0.3248],\n",
      "        [ 0.8454,  0.4059]], requires_grad=True)], Cost : 0.026\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 1.2330, -0.4224],\n",
      "        [ 0.8977,  0.3636]], requires_grad=True)], Cost : 0.017\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 1.3289, -0.4998],\n",
      "        [ 0.9392,  0.3300]], requires_grad=True)], Cost : 0.011\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 1.4051, -0.5615],\n",
      "        [ 0.9722,  0.3033]], requires_grad=True)], Cost : 0.007\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 1.4656, -0.6104],\n",
      "        [ 0.9985,  0.2821]], requires_grad=True)], Cost : 0.004\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 1.5137, -0.6493],\n",
      "        [ 1.0193,  0.2653]], requires_grad=True)], Cost : 0.003\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 1.5520, -0.6803],\n",
      "        [ 1.0359,  0.2519]], requires_grad=True)], Cost : 0.002\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 1.5823, -0.7048],\n",
      "        [ 1.0490,  0.2412]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 11000, Model : [Parameter containing:\n",
      "tensor([[ 1.6065, -0.7244],\n",
      "        [ 1.0595,  0.2328]], requires_grad=True)], Cost : 0.001\n",
      "Epoch : 12000, Model : [Parameter containing:\n",
      "tensor([[ 1.6257, -0.7399],\n",
      "        [ 1.0678,  0.2260]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 13000, Model : [Parameter containing:\n",
      "tensor([[ 1.6409, -0.7522],\n",
      "        [ 1.0744,  0.2207]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 14000, Model : [Parameter containing:\n",
      "tensor([[ 1.6531, -0.7620],\n",
      "        [ 1.0797,  0.2164]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 15000, Model : [Parameter containing:\n",
      "tensor([[ 1.6627, -0.7698],\n",
      "        [ 1.0838,  0.2131]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 16000, Model : [Parameter containing:\n",
      "tensor([[ 1.6704, -0.7760],\n",
      "        [ 1.0872,  0.2104]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 17000, Model : [Parameter containing:\n",
      "tensor([[ 1.6764, -0.7809],\n",
      "        [ 1.0898,  0.2083]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 18000, Model : [Parameter containing:\n",
      "tensor([[ 1.6813, -0.7849],\n",
      "        [ 1.0919,  0.2066]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 19000, Model : [Parameter containing:\n",
      "tensor([[ 1.6851, -0.7880],\n",
      "        [ 1.0936,  0.2052]], requires_grad=True)], Cost : 0.000\n",
      "Epoch : 20000, Model : [Parameter containing:\n",
      "tensor([[ 1.6882, -0.7904],\n",
      "        [ 1.0949,  0.2041]], requires_grad=True)], Cost : 0.000\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(2, 2, bias=False)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        x, y = batch\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost /= len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델/데이터세트 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비선형회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.36 - 사용자 정의 데이터세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        self.x = df.iloc[:, 0].values\n",
    "        self.y = df.iloc[:, 1].values\n",
    "        self.length = len(df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = torch.FloatTensor([self.x[index]**2, self.x[index]])\n",
    "        y = torch.FloatTensor([self.y[index]])\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.37 - 사용자 정의 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(2,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.38 - 사용자 정의 데이터세트와 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\"../data/non_linear.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.39 - GPU 연산 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.40 - 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[ 3.0982, -1.7012]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5934], device='cuda:0', requires_grad=True)], Cost : 0.079\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[ 3.0985, -1.7033]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5849], device='cuda:0', requires_grad=True)], Cost : 0.078\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 3.0986, -1.7034]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5773], device='cuda:0', requires_grad=True)], Cost : 0.077\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 3.0986, -1.7033]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5702], device='cuda:0', requires_grad=True)], Cost : 0.079\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 3.0986, -1.7031]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5637], device='cuda:0', requires_grad=True)], Cost : 0.080\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 3.0989, -1.7033]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5579], device='cuda:0', requires_grad=True)], Cost : 0.075\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 3.0991, -1.7035]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5525], device='cuda:0', requires_grad=True)], Cost : 0.069\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 3.0990, -1.7034]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5475], device='cuda:0', requires_grad=True)], Cost : 0.075\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 3.0992, -1.7033]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5430], device='cuda:0', requires_grad=True)], Cost : 0.071\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 3.0992, -1.7033]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5388], device='cuda:0', requires_grad=True)], Cost : 0.088\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost /= len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.41 - 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.9347],\n",
       "        [ 69.5021],\n",
       "        [356.8043]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = torch.FloatTensor(\n",
    "        [\n",
    "            [1 ** 2, 1],\n",
    "            [5 ** 2, 5],\n",
    "            [11 ** 2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs = model(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.42 - 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"../models/\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "torch.save(model, path + \"model.pt\")\n",
    "torch.save(model.state_dict(), path + \"model_state_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터세트 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.44 - 데이터세트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 160\n",
      "Validation Data Size: 20\n",
      "Test Data Size: 20\n",
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[ 3.1055, -1.7042]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1135], device='cuda:0', requires_grad=True)], Cost : 0.141\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[ 3.1024, -1.7049]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.3327], device='cuda:0', requires_grad=True)], Cost : 0.094\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 3.1015, -1.7050]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4259], device='cuda:0', requires_grad=True)], Cost : 0.080\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 3.1001, -1.7052]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4657], device='cuda:0', requires_grad=True)], Cost : 0.077\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 3.0999, -1.7053]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4825], device='cuda:0', requires_grad=True)], Cost : 0.078\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 3.0995, -1.7053]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4897], device='cuda:0', requires_grad=True)], Cost : 0.079\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 3.0993, -1.7052]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4927], device='cuda:0', requires_grad=True)], Cost : 0.079\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 3.1006, -1.7053]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4941], device='cuda:0', requires_grad=True)], Cost : 0.080\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 3.1007, -1.7053]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4946], device='cuda:0', requires_grad=True)], Cost : 0.079\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 3.1002, -1.7053]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4948], device='cuda:0', requires_grad=True)], Cost : 0.080\n",
      "X : tensor([[ 1.4440e+01,  3.8000e+00],\n",
      "        [ 9.0250e+01,  9.5000e+00],\n",
      "        [ 1.0000e-02,  1.0000e-01],\n",
      "        [ 1.4400e+00, -1.2000e+00]], device='cuda:0')\n",
      "Y : tensor([[ 38.7700],\n",
      "        [263.8000],\n",
      "        [  0.6600],\n",
      "        [  6.6500]], device='cuda:0')\n",
      "Outputs : tensor([[ 38.7815],\n",
      "        [264.0872],\n",
      "        [  0.3553],\n",
      "        [  7.0054]], device='cuda:0')\n",
      "--------------------\n",
      "X : tensor([[ 6.7600, -2.6000],\n",
      "        [ 8.4100, -2.9000],\n",
      "        [ 7.2900, -2.7000],\n",
      "        [ 7.2900,  2.7000]], device='cuda:0')\n",
      "Y : tensor([[26.2000],\n",
      "        [31.8300],\n",
      "        [27.6000],\n",
      "        [18.2600]], device='cuda:0')\n",
      "Outputs : tensor([[25.8859],\n",
      "        [31.5128],\n",
      "        [27.6995],\n",
      "        [18.4909]], device='cuda:0')\n",
      "--------------------\n",
      "X : tensor([[ 1.6900,  1.3000],\n",
      "        [17.6400,  4.2000],\n",
      "        [12.2500, -3.5000],\n",
      "        [11.5600,  3.4000]], device='cuda:0')\n",
      "Y : tensor([[ 3.3000],\n",
      "        [48.3700],\n",
      "        [44.2800],\n",
      "        [30.6800]], device='cuda:0')\n",
      "Outputs : tensor([[ 3.5172],\n",
      "        [48.0200],\n",
      "        [44.4408],\n",
      "        [30.5350]], device='cuda:0')\n",
      "--------------------\n",
      "X : tensor([[24.0100, -4.9000],\n",
      "        [47.6100, -6.9000],\n",
      "        [53.2900, -7.3000],\n",
      "        [ 2.2500, -1.5000]], device='cuda:0')\n",
      "Y : tensor([[ 83.2800],\n",
      "        [160.0900],\n",
      "        [177.7300],\n",
      "        [  9.9600]], device='cuda:0')\n",
      "Outputs : tensor([[ 83.2865],\n",
      "        [159.8618],\n",
      "        [178.1530],\n",
      "        [ 10.0282]], device='cuda:0')\n",
      "--------------------\n",
      "X : tensor([[12.2500,  3.5000],\n",
      "        [ 0.0900, -0.3000],\n",
      "        [67.2400,  8.2000],\n",
      "        [ 0.3600,  0.6000]], device='cuda:0')\n",
      "Y : tensor([[ 32.2700],\n",
      "        [  1.4900],\n",
      "        [195.2000],\n",
      "        [  0.2600]], device='cuda:0')\n",
      "Outputs : tensor([[ 32.5036],\n",
      "        [  1.2854],\n",
      "        [194.9686],\n",
      "        [  0.5877]], device='cuda:0')\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(\"../data/non_linear.csv\")\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "print(f\"Training Data Size: {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size: {len(validation_dataset)}\")\n",
    "print(f\"Test Data Size: {len(test_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost /= len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for x, y in validation_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        outputs = model(x)\n",
    "        print(f\"X : {x}\")\n",
    "        print(f\"Y : {y}\")\n",
    "        print(f\"Outputs : {outputs}\")\n",
    "        print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 전체 저장/불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.47 - 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (layer): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[  1.9347],\n",
      "        [ 69.5021],\n",
      "        [356.8043]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HyeAnn\\AppData\\Local\\Temp\\ipykernel_28096\\1567141737.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(path + \"model.pt\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(path + \"model.pt\", map_location=device)\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = torch.FloatTensor(\n",
    "        [\n",
    "            [1 ** 2, 1],\n",
    "            [5 ** 2, 5],\n",
    "            [11 ** 2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs = model(inputs)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 상태 저장/불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.50 - 모델 상태 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HyeAnn\\AppData\\Local\\Temp\\ipykernel_28096\\2821190327.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_state_dict = torch.load(path+\"model_state_dict.pt\", map_location=device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.9347],\n",
       "        [ 69.5021],\n",
       "        [356.8043]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomModel().to(device)\n",
    "model_state_dict = torch.load(path+\"model_state_dict.pt\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    inputs = torch.FloatTensor(\n",
    "        [\n",
    "            [1 ** 2, 1],\n",
    "            [5 ** 2, 5],\n",
    "            [11 ** 2, 11]\n",
    "        ]\n",
    "    ).to(device)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 체크포인트 저장/불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1000, Model : [Parameter containing:\n",
      "tensor([[ 3.1086, -1.7001]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0021], device='cuda:0', requires_grad=True)], Cost : 0.163\n",
      "Epoch : 2000, Model : [Parameter containing:\n",
      "tensor([[ 3.1074, -1.7026]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0438], device='cuda:0', requires_grad=True)], Cost : 0.154\n",
      "Epoch : 3000, Model : [Parameter containing:\n",
      "tensor([[ 3.1069, -1.7028]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0821], device='cuda:0', requires_grad=True)], Cost : 0.162\n",
      "Epoch : 4000, Model : [Parameter containing:\n",
      "tensor([[ 3.1061, -1.7028]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1170], device='cuda:0', requires_grad=True)], Cost : 0.159\n",
      "Epoch : 5000, Model : [Parameter containing:\n",
      "tensor([[ 3.1054, -1.7030]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1491], device='cuda:0', requires_grad=True)], Cost : 0.128\n",
      "Epoch : 6000, Model : [Parameter containing:\n",
      "tensor([[ 3.1048, -1.7030]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1785], device='cuda:0', requires_grad=True)], Cost : 0.115\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 3.1047, -1.7028]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2053], device='cuda:0', requires_grad=True)], Cost : 0.094\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 3.1047, -1.7029]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2298], device='cuda:0', requires_grad=True)], Cost : 0.109\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 3.1041, -1.7030]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2523], device='cuda:0', requires_grad=True)], Cost : 0.099\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 3.1036, -1.7032]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2729], device='cuda:0', requires_grad=True)], Cost : 0.100\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(\"../data/non_linear.csv\")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "checkpoint = 1\n",
    "\n",
    "for epoch in range(10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost /= len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")\n",
    "        torch.save({\n",
    "            \"model\" : \"CustomModel\",\n",
    "            \"epoch\" : epoch,\n",
    "            \"model_state_dict\" : model.state_dict(),\n",
    "            \"optimizer_state_dict\" : optimizer.state_dict(),\n",
    "            \"cost\" : cost,\n",
    "            \"description\" : f\"CustomModel checkpoint - {checkpoint}\",\n",
    "        }, path+f\"checkpoint-{checkpoint}.pt\",\n",
    "        )\n",
    "        checkpoint += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제 3.52 - 체크포인트 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HyeAnn\\AppData\\Local\\Temp\\ipykernel_28096\\255518434.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path+\"checkpoint-6.pt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel checkpoint - 6\n",
      "Epoch : 7000, Model : [Parameter containing:\n",
      "tensor([[ 3.1047, -1.7031]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2053], device='cuda:0', requires_grad=True)], Cost : 0.109\n",
      "Epoch : 8000, Model : [Parameter containing:\n",
      "tensor([[ 3.1044, -1.7029]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2300], device='cuda:0', requires_grad=True)], Cost : 0.106\n",
      "Epoch : 9000, Model : [Parameter containing:\n",
      "tensor([[ 3.1039, -1.7032]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2525], device='cuda:0', requires_grad=True)], Cost : 0.104\n",
      "Epoch : 10000, Model : [Parameter containing:\n",
      "tensor([[ 3.1034, -1.7029]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2731], device='cuda:0', requires_grad=True)], Cost : 0.100\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(path+\"checkpoint-6.pt\")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "checkpoint_epoch = checkpoint[\"epoch\"]\n",
    "checkpoint_description = checkpoint[\"description\"]\n",
    "print(checkpoint_description)\n",
    "\n",
    "for epoch in range(checkpoint_epoch + 1, 10000):\n",
    "    cost = 0.0\n",
    "\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cost += loss\n",
    "\n",
    "    cost /= len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f\"Epoch : {epoch+1:4d}, Model : {list(model.parameters())}, Cost : {cost:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✔ 오늘 새로 알게된 부분이 있다면 간략히 설명해주세요.\n",
    "\n",
    "- `Dataset`과 `Dataloader`를 사용하는 이유 : 데이터를 학습에 직접 사용하면 모듈화, 재사용성, 가독성 등을 떨어뜨리게 된다\n",
    "- `Dataset` 클래스는 `init`, `getitem`, `len` 등의 내장 method가 필요하다.\n",
    "- `Dataloader`는 `batch_size`, `shuffle`, `num_workers` 등을 제공한다.\n",
    "- `torch.util.data.DataLoader`의 `drop_last` : 배치 크기에 맞지 않는 배치를 제거\n",
    "- 모델 구현은 `nn.Module` 클래스를 상속받아 사용한다. `init`과 `forward`만 구현하고 `backward`는 구현하지 않아도 된다. `init`에서 `super` 함수로 부모 클래스를 초기화했을 것이므로, 파이토치의 자동 미분 기능인 Autograd에서 모델의 매개변수를 역으로 전파해 자동으로 기울기 또는 변화도를 계산해준다.\n",
    "- 학습 중간에 `eval` 메서드를 사용하여 모델 평가 모드를 진행한 다음 다시 학습을 진행하려는 경우 `train` 메서드를 통해 학습 모드로 변경해야 한다.\n",
    "- 모델을 저장하려면 `Pickle`을 활용해 python object 구조를 binary protocol로 직렬화한다. 모델을 불러오려면 저장된 object 파일을 역직렬화해 현재 프로세스의 메모리에 업로드한다.\n",
    "- 모델 전체를 저장하면 모델의 모든 정보를 저장하므로 모델 상태만 저장하는 것보다 더 많은 저장 공간이 필요하다. 모델 상태 (`torch.state_dict`)는 모델에서 학습이 가능한 매개변수를 `OrderedDict` 형식으로 반환한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wikibooks-pytorch-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
